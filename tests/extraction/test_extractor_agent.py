import pytest
from pathlib import Path
from pydantic import ValidationError

from textura.extraction.extractor_agent import ExtractorAgent
from textura.extraction.models import EventV1, MysteryV1, PersonV1, LocationV1, OrganizationV1, ExtractionItem
from textura.extraction.prompts import SCHEMA_FIRST_EXTRACTION_PROMPT
from textura.logging.metacog import Metacog
from textura.llm_clients.types import (
    LLMResponse, FunctionCall,
    Tool as TexturaTool, # Though tools are generated by agent, not directly made in test
    FunctionDeclaration as TexturaFunctionDeclaration,
    FunctionParameters as TexturaFunctionParameters,
    FunctionParameterProperty as TexturaFunctionParameterProperty
)
from tests.mocks.mock_llm_service import MockLLMService

# --- Direct Pydantic Model Validation Tests ---
# These remain unchanged as they test models directly, not the agent.

def test_person_model_validation():
    """Test direct Pydantic validation for PersonV1."""
    # Valid data
    person = PersonV1(name="John Doe", title="Dr.", role="Lead", source_file="s.txt", chunk_id="c1")
    assert person.name == "John Doe"
    assert person.title == "Dr."

    # Missing name
    with pytest.raises(ValidationError) as excinfo:
        PersonV1(title="Mr.", source_file="s.txt", chunk_id="c1")
    assert "name" in str(excinfo.value).lower()
    assert "field required" in str(excinfo.value).lower()

    # Name not a string
    with pytest.raises(ValidationError) as excinfo:
        PersonV1(name=123, source_file="s.txt", chunk_id="c1")
    assert "name" in str(excinfo.value).lower()
    assert "string type expected" in str(excinfo.value).lower()

def test_location_model_validation():
    """Test direct Pydantic validation for LocationV1."""
    location = LocationV1(name="Area 51", type="Military Base", source_file="s.txt", chunk_id="c1")
    assert location.name == "Area 51"

    with pytest.raises(ValidationError) as excinfo:
        LocationV1(type="Unknown", source_file="s.txt", chunk_id="c1")
    assert "name" in str(excinfo.value).lower()
    assert "field required" in str(excinfo.value).lower()

def test_organization_model_validation():
    """Test direct Pydantic validation for OrganizationV1."""
    org = OrganizationV1(name="Acme Corp", industry="Manufacturing", source_file="s.txt", chunk_id="c1")
    assert org.name == "Acme Corp"

    with pytest.raises(ValidationError) as excinfo:
        OrganizationV1(industry="Tech", source_file="s.txt", chunk_id="c1")
    assert "name" in str(excinfo.value).lower()
    assert "field required" in str(excinfo.value).lower()


# --- ExtractorAgent Tests ---

@pytest.fixture
def metacog_logger(test_workspace: Path) -> Metacog:
    """Fixture to provide a Metacog logger instance for tests."""
    return Metacog(workspace_path=str(test_workspace))

@pytest.fixture
def mock_llm() -> MockLLMService:
    """Fixture to provide a MockLLMService instance."""
    return MockLLMService()

# Helper function to check Metacog logs
def check_metacog_log(metacog_logger: Metacog, expected_strings: list[str], not_expected_strings: list[str] = None):
    log_file = metacog_logger.log_file_path
    assert log_file.exists()
    with open(log_file, 'r') as f:
        log_content = f.read()
    for s in expected_strings:
        assert s in log_content
    if not_expected_strings:
        for s in not_expected_strings:
            assert s not in log_content

def test_extractor_agent_extracts_event(metacog_logger: Metacog, mock_llm: MockLLMService):
    """Test ExtractorAgent can extract a valid EventV1 using tool call flow."""
    agent = ExtractorAgent(metacog_logger=metacog_logger, llm_client=mock_llm) # Pass mock_llm as the client
    chunk_text = "An event happened on July 4th."
    chunk_id = "test_chunk_001"
    source_file = "test_doc.txt"
    formatted_prompt = SCHEMA_FIRST_EXTRACTION_PROMPT.format(text_chunk_content=chunk_text)

    mock_llm.set_response(formatted_prompt, LLMResponse(
        function_calls=[FunctionCall(
            name="event",
            arguments={"timestamp": "July 4th", "description": "Fireworks display observed."}
        )]
    ))
    extractions = agent.extract_from_chunk(chunk_text, chunk_id, source_file)

    assert len(extractions) == 1
    extracted_item = extractions[0]
    assert isinstance(extracted_item, EventV1)
    assert extracted_item.description == "Fireworks display observed."
    assert extracted_item.timestamp == "July 4th"
    assert extracted_item.source_file == source_file
    assert extracted_item.chunk_id == chunk_id

    assert mock_llm.call_count == 1
    last_request = mock_llm.get_last_request()
    assert last_request["prompt"] == formatted_prompt
    assert last_request["method"] == "predict_with_tools"
    assert last_request["tools_provided_count"] > 0
    check_metacog_log(metacog_logger, ["Fireworks display observed.", "\"errors\": []"])


def test_extractor_agent_extracts_person(metacog_logger: Metacog, mock_llm: MockLLMService):
    agent = ExtractorAgent(metacog_logger=metacog_logger, llm_client=mock_llm)
    chunk_text = "Dr. John Doe was present."
    chunk_id = "person_chunk_001"
    source_file = "person_doc.txt"
    formatted_prompt = SCHEMA_FIRST_EXTRACTION_PROMPT.format(text_chunk_content=chunk_text)

    mock_llm.set_response(formatted_prompt, LLMResponse(
        function_calls=[FunctionCall(
            name="person",
            arguments={"name": "Dr. John Doe", "title": "Dr.", "role": "Attendee"}
        )]
    ))
    extractions = agent.extract_from_chunk(chunk_text, chunk_id, source_file)

    assert len(extractions) == 1
    item = extractions[0]
    assert isinstance(item, PersonV1)
    assert item.name == "Dr. John Doe"
    check_metacog_log(metacog_logger, ["Dr. John Doe", "\"errors\": []"])
    assert mock_llm.get_last_request()["method"] == "predict_with_tools"


def test_extractor_agent_extracts_location(metacog_logger: Metacog, mock_llm: MockLLMService):
    agent = ExtractorAgent(metacog_logger=metacog_logger, llm_client=mock_llm)
    chunk_text = "The meeting was in Building A."
    chunk_id = "loc_chunk_001"
    source_file = "loc_doc.txt"
    formatted_prompt = SCHEMA_FIRST_EXTRACTION_PROMPT.format(text_chunk_content=chunk_text)

    mock_llm.set_response(formatted_prompt, LLMResponse(
        function_calls=[FunctionCall(
            name="location",
            arguments={"name": "Building A", "type": "Office Building"}
        )]
    ))
    extractions = agent.extract_from_chunk(chunk_text, chunk_id, source_file)
    assert len(extractions) == 1
    item = extractions[0]
    assert isinstance(item, LocationV1)
    assert item.name == "Building A"
    check_metacog_log(metacog_logger, ["Building A", "\"errors\": []"])
    assert mock_llm.get_last_request()["method"] == "predict_with_tools"


def test_extractor_agent_extracts_organization(metacog_logger: Metacog, mock_llm: MockLLMService):
    agent = ExtractorAgent(metacog_logger=metacog_logger, llm_client=mock_llm)
    chunk_text = "Acme Corp announced profits."
    chunk_id = "org_chunk_001"
    source_file = "org_doc.txt"
    formatted_prompt = SCHEMA_FIRST_EXTRACTION_PROMPT.format(text_chunk_content=chunk_text)

    mock_llm.set_response(formatted_prompt, LLMResponse(
        function_calls=[FunctionCall(
            name="organization",
            arguments={"name": "Acme Corp", "industry": "Manufacturing"}
        )]
    ))
    extractions = agent.extract_from_chunk(chunk_text, chunk_id, source_file)
    assert len(extractions) == 1
    item = extractions[0]
    assert isinstance(item, OrganizationV1)
    assert item.name == "Acme Corp"
    check_metacog_log(metacog_logger, ["Acme Corp", "\"errors\": []"])
    assert mock_llm.get_last_request()["method"] == "predict_with_tools"


def test_extractor_agent_extracts_mixed_entities(metacog_logger: Metacog, mock_llm: MockLLMService):
    agent = ExtractorAgent(metacog_logger=metacog_logger, llm_client=mock_llm)
    chunk_text = "Event at Acme Corp involving Dr. Doe in the Main Hall."
    chunk_id = "mixed_chunk_001"
    source_file = "mixed_doc.txt"
    formatted_prompt = SCHEMA_FIRST_EXTRACTION_PROMPT.format(text_chunk_content=chunk_text)

    mock_llm.set_response(formatted_prompt, LLMResponse(
        function_calls=[
            FunctionCall(name="event", arguments={"timestamp": "today", "description": "Keynote"}),
            FunctionCall(name="person", arguments={"name": "Dr. Doe", "role": "Speaker"}),
            FunctionCall(name="location", arguments={"name": "Main Hall", "type": "Venue"}),
            FunctionCall(name="organization", arguments={"name": "Acme Corp"})
        ]
    ))
    extractions = agent.extract_from_chunk(chunk_text, chunk_id, source_file)
    assert len(extractions) == 4
    assert any(isinstance(item, EventV1) and item.description == "Keynote" for item in extractions)
    assert any(isinstance(item, PersonV1) and item.name == "Dr. Doe" for item in extractions)
    check_metacog_log(metacog_logger, ["Keynote", "Dr. Doe", "Main Hall", "Acme Corp", "\"errors\": []"])
    assert mock_llm.get_last_request()["method"] == "predict_with_tools"


def test_extractor_agent_handles_validation_error(metacog_logger: Metacog, mock_llm: MockLLMService):
    agent = ExtractorAgent(metacog_logger=metacog_logger, llm_client=mock_llm)
    chunk_text = "This data will be invalid for an event."
    chunk_id = "test_chunk_002"
    source_file = "test_doc_invalid.txt"
    formatted_prompt = SCHEMA_FIRST_EXTRACTION_PROMPT.format(text_chunk_content=chunk_text)

    mock_llm.set_response(formatted_prompt, LLMResponse(
        function_calls=[FunctionCall(name="event", arguments={"timestamp": "Tomorrow"})] # Missing description
    ))
    extractions = agent.extract_from_chunk(chunk_text, chunk_id, source_file)
    assert len(extractions) == 0
    check_metacog_log(metacog_logger, ["ValidationErrorFromFunctionCall", "description", "Field required"])
    assert mock_llm.get_last_request()["method"] == "predict_with_tools"


def test_extractor_agent_handles_person_validation_error(metacog_logger: Metacog, mock_llm: MockLLMService):
    agent = ExtractorAgent(metacog_logger=metacog_logger, llm_client=mock_llm)
    chunk_text = "This data will be invalid for a person."
    chunk_id = "invalid_person_chunk"
    source_file = "invalid_person_doc.txt"
    formatted_prompt = SCHEMA_FIRST_EXTRACTION_PROMPT.format(text_chunk_content=chunk_text)

    mock_llm.set_response(formatted_prompt, LLMResponse(
        function_calls=[FunctionCall(name="person", arguments={"title": "The Nameless"})] # Missing 'name'
    ))
    extractions = agent.extract_from_chunk(chunk_text, chunk_id, source_file)
    assert len(extractions) == 0
    check_metacog_log(metacog_logger, ["ValidationErrorFromFunctionCall", "name", "Field required", "person"])
    assert mock_llm.get_last_request()["method"] == "predict_with_tools"

# It might be good to add similar validation error tests for LocationV1 and OrganizationV1 if they
# have more complex validation rules beyond 'name' being required, or for completeness.

def test_agent_handles_llm_text_response_when_tools_used(metacog_logger: Metacog, mock_llm: MockLLMService):
    """Tests agent behavior when LLM returns text instead of a function call, with tools provided."""
    agent = ExtractorAgent(metacog_logger=metacog_logger, llm_client=mock_llm)
    chunk_text = "Some query for the LLM."
    chunk_id = "text_response_chunk"
    source_file = "text_response_doc.txt"
    formatted_prompt = SCHEMA_FIRST_EXTRACTION_PROMPT.format(text_chunk_content=chunk_text)

    mock_llm.set_response(formatted_prompt, LLMResponse(text="LLM decided to just talk instead of calling a tool."))
    extractions = agent.extract_from_chunk(chunk_text, chunk_id, source_file)

    assert len(extractions) == 0
    check_metacog_log(metacog_logger, ["TextResponseFromLLM", "LLM decided to just talk"])
    assert mock_llm.get_last_request()["method"] == "predict_with_tools"

def test_agent_handles_unsupported_function_call(metacog_logger: Metacog, mock_llm: MockLLMService):
    """Tests agent behavior when LLM calls a function not in the agent's model_map."""
    agent = ExtractorAgent(metacog_logger=metacog_logger, llm_client=mock_llm)
    chunk_text = "Query that might trigger an unknown function."
    chunk_id = "unknown_func_chunk"
    source_file = "unknown_func_doc.txt"
    formatted_prompt = SCHEMA_FIRST_EXTRACTION_PROMPT.format(text_chunk_content=chunk_text)

    mock_llm.set_response(formatted_prompt, LLMResponse(
        function_calls=[FunctionCall(name="unknown_function", arguments={"param": "value"})]
    ))
    extractions = agent.extract_from_chunk(chunk_text, chunk_id, source_file)

    assert len(extractions) == 0
    check_metacog_log(metacog_logger, ["UnsupportedFunctionCall", "unknown_function"])
    assert mock_llm.get_last_request()["method"] == "predict_with_tools"
